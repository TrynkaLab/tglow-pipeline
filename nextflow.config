// ---------------------------------------------------------------------------------- //
//                             Nextflow / executor settings
// ---------------------------------------------------------------------------------- //
conda.enabled = true
manifest.mainScript = "tglow.nf"

profiles {
    local { includeConfig 'conf/local.config'}
    lsf { includeConfig 'conf/lsf.config'}
    lsf_ignore_errors { includeConfig 'conf/lsf_ignore_errors.config'}
}

report.overwrite=true
trace.overwrite=true

// ---------------------------------------------------------------------------------- //
//                                    Process labels
// ---------------------------------------------------------------------------------- //
includeConfig 'conf/processes.config'

// ---------------------------------------------------------------------------------- //
//                                      Parameters
// ---------------------------------------------------------------------------------- //
params {

    // ---------------------------------------------------------------------------------- //
    //                          Run specific parameters
    // ---------------------------------------------------------------------------------- //
    // Core manifest
    // set bp_channels to none to not run basicpy
    // set cp_cell_channel to none to not run cellpose
    // set cp_nucl_channel to none to run cellpose without a nucleus channel
    // If a registration manifest is provided, only reference plates will be run through cellpose
    // <plate>	<index_xml>	<channels>	<bp_channels>	<cp_nucl_channel>	<cp_cell_channel>	<dc_channels>	<dc_psfs>	<mask_channels>	<scale_factors>
    rn_manifest=null
    
    // Well level manifest (blacklist), supply path to file.
    // Specifying which wells to ignore. This is usefull to deal with edgecases in a plate or 
    // single stain controls etc. you don't want to analyze.
    // Leave at null to ingore.
    // <plate> <well>
    // plate1   A09
    // plate2   A09
    // plate2   D12
    rn_blacklist=null

    // Control file to use to calculate plate offsets based on control cells for each channel
    // <plate> <well> <channels> <name>
    // plate1   A10 1,2,3   controlA
    // plate1   B10 1,2,3   controlA
    // plate1   C10 1,2,3   controlA
    // plate1   D11 5,6,7   controlB
    // plate1   D12 5,6,7   controlB
    rn_control_list=null

    // Well level manifest (whitelist)
    // This is a file with <well> <plate> <pe xml> structure indicating which wells on which plates to run
    // Set to null if auto generated from perking elmer XML
    // If not null, supply a list /path/to/plate1_manifest.csv,/path/to/plate2_manifest.csv,...
    rn_manifest_well=null
    
    // Registration manifest
    // This dicates which plates will be merged and registered. If left to null
    // no merging or registration is performed
    rn_manifest_registration=null

    // Results / publish dir
    // The root of where to publish results
    // rn_publish_dir

    // Permanent cache for images [optional]
    // Defaults to: ${rn_publish_dir}/images
    rn_image_dir=null
    
    // Permanent cache for deconvolutions [optional]
    // Defaults to: ${rn_publish_dir}/decon
    rn_decon_dir=null
    
    // Max project prior to running segmentation and cellprofiler
    // Decon is still done in 3d, but results are saved as max projections.
    rn_max_project=false
    
    // Run in hybrid 2d/3d mode. Masks and decon run and saved in 3d but only
    // cellprofiler is run using max projections. In true ignores rn_max_project.
    // Must be true to enable demultipexing of nuclear and non-nuclear signals.
    rn_hybrid=false
    
    // Select only these wells, usefull for testing [optional]
    // comma seperated string of well ids: A06,B19,C22
    rn_wells=null
    
    // Use scratch space for most workdir operations, which saves IO load on networked
    // filesystems. But this makes debugging harder as tmp results are not available
    rn_scratch=true
    
    // Cache the final output images (flatflied, decon, demultiplexed, registered, scaled, max_projected)
    // They are saved as plate/row/col/field.ome.tiff in CZYX with additional cycle channels seqeunatially added.
    // If storage is a concern, disable this and enable rn_scratch to not save large intermediates.
    //
    // NOTE: When mode is hybrid or max project, the storage this generates will not be that bad, so its enabled by default.
    // NOTE: This must be true when running subcell, but as subcell only works with max projected images, the storage overhead should be ok
    // NOTE: These are not directly compatible with cellprofiler when working in 3d as they are saved in .ome.tiff 
    // for pipeline compatibility, which CPR does not handle.
    // Prior to running cellprofiler they are split up into <field>_<plate>_<well>_ch<channel>.tiff
    // which is compatible with both 2d and 3d formats. Use this pattern to setup your pipeline.
    rn_cache_images=true
    
    // Path to scaling_factors.txt which has one line formatted
    // <plate>_ch<channnel>=<scale> <plate>_ch<channnel>=<scale> <plate>_ch<channnel>=<scale>
    // - Space seperated
    // - Channels are zero indexed
    // - <plate> should be the reference plate
    // - <channel> should be the channel after merging cycles
    // - <scale> is the factor by which that channel in that plate is divided
    rn_manualscale=null
    
    // Path to scaling_<slope/bias>.txt which has one line formatted
    // <plate>_ch<channnel>=<slope/bias> <plate>_ch<channnel>=<slope/bias> <plate>_ch<channnel>=<slope/bias>
    // This sets the shape of the sigmoid curve used to weigh the scaling factors differently in intensity ranges
    // The idea is that background pixels remain unscaled, while there is a smooth transition into scaling foreground pixels.
    // Currently, the pipleine only supports pre-caculated values for slope and bias, and cannot auto-estimate them.
    // This works with both --rn_manualscale and --rn_autoscale
    // If supplied, must supply both. If left at null, scaling_factors are applied uniformly to the image
    rn_scale_slope=null
    rn_scale_bias=null
    
    // Automatically determine scaling factors based on all images in the manifest (excluding blacklist)
    // rn_autoscale_q1 controls the value to scale to within an image (i.e. the quantiles of the pixels)
    // rn_autoscale_q2 controls which quantile is taking across all the images in the set for the chosen q1
    // rn_autoscale_q1 Valid options are: 'q0', 'q0.1' 'q1', 'q5', 'q25', 'q50', 'q75', 'q90', 'q99', 'q99.9', 'q99.99', 'q99.999', 'q99.9999','q99.99999', 'q100', 'mean'
    // rn_autoscale_q2 Valid options are: 0 - 1
    // Note, not all valid options of rn_autoscale_q1 are practically sensible, I would not go below q99 in practice!
    
    // Reccomend q99.9999,95 which will ensure that 95% of the images will have 99.9999% of their pixels
    // within the dynamic range, any pixels above will be clipped.
    
    // For example with q99.9999
    // In a 2160x2160 image this means a maximum of ~467 pixels (2160x2160x0.0001) are allowed to be outside of the range of uint16.
    // It is often desirable to not choose q100 if you expect blobs or outlier pixels in your images with much higher intensities then your actual image.
    // If you have many outlier images or debris you can relax this, or manually provide scaling factors in the manifest.
    // If you want to ensure no dynamic range is lost use q100, 100. 

    // NOTE: This step runs AFTER dc_clip_max is applied, so if it clips values, the output here will 
    // also be clipped.
    // NOTE: rn_autoscale overrides rn_manualscale
    // NOTE: rn_autoscale will wait till the deconvelution queue is empty, so no feature extraction jobs
    // will be submitted until autoscale completes. 
    // NOTE: rn_autoscale interacts with rn_controllist so the dynamic range is most optimal after considering
    // plate offset factors. When rn_controllist is provided, rn_autoscale is on by default.
    rn_autoscale=false
    rn_autoscale_q1="q99.9999"
    rn_autoscale_q2=95
    
    // Generate plate offsets in dummy mode (returns all 1's for equal scaling, just for testing)
    rn_dummy_mode=false
    
    // When calculating plate offsets, should channel images be thresholded prior to calculating
    // mean object intensities. Background regions are then ignored. Otsu threshold on whole
    // image is used.
    rn_threshold=false

    // ---------------------------------------------------------------------------------- //
    //                                      Stage
    // ---------------------------------------------------------------------------------- //
    st_label="small_img"
    
    // ---------------------------------------------------------------------------------- //
    //                                Flatield estimation
    // ---------------------------------------------------------------------------------- //
    // Run flatfield estimation or not. Overrides the manifest
    bp_run=true
    
    // Resource label
    bp_label="himem"
    
    
    // Fit one flatfield per plate-channel, or one global flatfield per channel shared among the plates
    bp_global_flatfield=false
    
    // Mode, one of BASICPY | POLY | PE
    // BASICPY: Runs flatfields using basicpy
    // POLY: Fits a polynomial to either the whole image or the forground if --threshold is specified 
    // PE: Extract the flatfields from the plate's PE index
    bp_mode="POLY"
    
    // Should images be multi-otsu thresholded prior to fitting. Two top tiers treated as foreground.
    // This can be helpfull in sparse images, but can throw off the valuation procedure if there is a
    // strong flatfield that the otsu threshold does not deal with well, or there are outliers (debris)
    // in the image.
    //
    // # --mode BASICPY [NOT RECCOMENDED]
    // With basicpy the mask is supplied as fitting_weights arugments. This ensures only actual signal gets
    // fitted into the flatfield, avoiding that the flatfield fits to the background
    // 
    // # --mode POLY
    // The polynomial is only fit on foreground pixels. 
    bp_threshold=false
    
    // Degree for the polynomial (Should be either 2-4)
    // If it is <= 0 a special case is used where a model is fit in the form:
    //     # ^1    # ^2             # ^3                        # ^4
    // 1 + x + y + xy + x^2 + y^2 + x^3 + x^2*y + y^2*x + y^3 + x^4 + x^3*y + x^2*y^2 + y^3*x + y^4
    // This is the same polynomial that PE Harmony fits, otherwise numpy.polynomial.polynomial.polyvander2d
    // is used to generate the design matrix with given degree, which contains all possible combinations
    // of x^i * y^i, which can work, but is more likely to overfit as it produces more coefficients
    bp_degree=0
    
    // Channels to fit basicpy models on, leave null to run all channels specified in manifest (reccomended)
    // in manifest to not run basicpy for a plate, set channels to "none"
    // otherwise specify [[<plate>, <channel>, <index_xml>], ..., [<plate>, <channel>, <index_xml>]]
    // to override manifest
    bp_channels=null
    
    // Number of random images to read into memory. Sampled with replacement.
    // If no other option specified, this is the number of images flatfield is trained on
    // nimg_test does the same, but for a independent sampling used for testing flatfield
    // set bp_nimg_test=0 to skip flatfield evaluation
    bp_nimg=200    
    bp_nimg_test=100
    
    // Number of images to max project into a compound --nimg times.
    // If > 1 basicpy is run on --nimg images, each of which is a compound of --merge_n indiviual images
    // Set to null to run vanilla basicpy with no merging
    // This is usefull if your images are low density and the flatfields tend to be
    // the background signal rather then the foreground signal.
    // bp_nimg=100 and bp_merge_n=50 is a reasonable starting point, but milage may vary depending on density!!!
    // WARNING: Can randomly sample the same images into different compounds. I.e if your data has 100
    // images and you select --merge_n 50 on average, 25 images (0.5*0.5) will overlap
    bp_merge_n=null
    
    // Pseudoreplicate in memory
    // This is related to --merge_n, but instead of reading from disk, only --nimg images are read
    // then pseudoreplicate compound images of size --merge_n are made.
    // so if --pseudoreplicate 15 --nimg 100 --merge_n 10 basicpy is trained on 15 compound images
    // each consisting of the max projection of 10 images selected from a pool of 100 images.
    // sampling is done with replacement and overlap can exist between images, hence pseudoreplicates
    // the goal is similar to --merge_n but avoids major IO load at the risk of creating some similar images
    // set --nimg to a higish number to avoid this.
    // bp_pseudoreplicates_test works the same, but used in the draw for the flatfield evaluation
    bp_pseudoreplicates=null
    bp_pseudoreplicates_test=null
    
    // Use ridge regression instead of OLS to fit the polynomial. Uses RidgeCV and 10 fold CV to find optimal alpha
    bp_use_ridge=false
    
    // [NOT RECCOMENDED]
    // Instead of randomly picking one plane for a stack, use all planes.
    // This can give issues with basicpy as it does not like correlations too much and
    // assumes random variation between images. When rn_max_project is true all planes are
    // read and subseqeuntly max projected, so this is not an issue.
    bp_all_planes=false
    
    // [NOT RECCOMENDED | BP_ONLY]
    // Apply the basicpy autosegment option, basically the oposite of --threshold, except
    // this applies a mask erosion.
    bp_autosegment=false
    
    // [NOT RECCOMENDED | BP_ONLY]
    // Do not tune basicpy model
    bp_no_tune=false
    
    // ---------------------------------------------------------------------------------- //
    //                                      Cellpose
    // ---------------------------------------------------------------------------------- //
    // Process label for cellpose
    cp_label="gpu_normal"
    cp_run=true
    // Estimated cellsize for cellpose in pixels.
    // Set this to something resonable, these are estimates for T cells
    cp_cell_size=75
    
    // Estimated nucleus size for cellpose in pixels
    // Set this to something resonable, these are estimates for T cells
    cp_nucl_size=60
    
    // Cellpose model
    // The util was built on the cyto2 model and if possible will use a nucleus channel.
    // As such I can't confirm other models work, but in princple they should.
    cp_model="cyto2"
    
    // Cellpose min cell area in pixels
    // This the minimal area of the ROIs.
    // If null defaults to π (1/6th of cp_cell_size)^2 for 2d
    // If null defaults to 4/3π (1/6th of cp_cell_size)^3 for 3d
    cp_min_cell_area=null
    
    // Cellpose min nucl area in pixels
    // This the minimal area of the ROIs.
    // If null defaults to π (1/6th of cp_nucl_size)^2 for 2d
    // If null defaults to 4/3π (1/6th of cp_nucl_size)^3 for 3d
    cp_min_nucl_area=null
    
    // Fit a nucleus mask, but do not use the nuclei to declump objects in mask
    // creation.
    cp_dont_use_nucl_for_declump=false
    
    // [DEPRECATED] [EXPERIMENTAL]
    // Raise the cell or nucleus images to a power, and then scale.
    // This works as a form of soft thresholding in the case cellpose
    // fits the masks too strongly to noise. Which can be an option if tweaking the 
    // cellprob threshold doesn't work well enough or the post-processing doesn't work.
    cp_cell_power=null
    cp_nucl_power=null
    
    
    // [DEPRECATED] [EXPERIMENTAL]
    // To not post process the masks in 3d mode set to true.
    // If running in 3d mode some post-processing steps are applied to the nuclei if provided.
    // A local otsu thresholding is performed, after which holes in this are closed with a disk of 10 in 2d per plane
    // This mask is then multiplied with the cellpose masks to ensure they are well contained in the region
    // with signal, as cellpose in 3d was quite sensitive to z-bleedover due to residual signal of the PSF
    // which leads to incorrect masks.
    cp_dont_post_process=true
    
    // Downsample the images in YX prior to running cellpose. This will automatically
    // scale --diameter --anisotropy, --min_cell_area and --min_nucl_area to match.
    // This can have substantial speed improvements at the cost of decreased mask resolution.
    // Masks are scaled up using nearest neighbour interpolation.
    // Reccomened value would be integers that give a whole number in YX. 2 is a good bet.
    cp_downsample=null
    
    // Cellpose flow threshold for cell and nuclei runs
    // See cellpose docs for detaills
    cp_cell_flow_thresh=0.4
    cp_nucl_flow_thresh=0.4

    // Cellpose cellprob threshold for cell and nuclei runs
    // See cellpose docs for detaills (between -6, 6, higher is tighter masks, lower looser masks)
    cp_cell_prob_threshold=0
    cp_nucl_prob_threshold=0

    // ---------------------------------------------------------------------------------- //
    //                                      Registration
    // ---------------------------------------------------------------------------------- //
    // Reseouce label
    rg_label="normal"
    
    // Runs only if registration manifest is provided
    // Make images of the registration results
    rg_plot=true
    
    
    // Mode, use either skimage phase cross correlation or pystackreg with translation
    // CROSS | STACKREG
    rg_mode="CROSS"
    
    // Offsets in X and Y. Positive value will shift down (as per scipy.ndimage.shift)
    rg_offset_x=null
    rg_offset_y=null
    
    // Evaluate registration results pearson correlation between registration channels
    // Only really usefull if you have a lot of signals as images are mostly noise
    // TODO: Threshold the image first, then correlate 
    rg_eval=true
    
    
    
    // ---------------------------------------------------------------------------------- //
    //                                      Deconvolute
    // ---------------------------------------------------------------------------------- //
    // Decon resource label
    dc_label="gpu_normal"

    // Run deconvolution or not
    dc_run=false
    
    // Point spread functions, better configured through manifest
    // Leave null to not run deconvolutin.
    dc_psfs=null
    
    // Number of iterations to run richardson lucy deconvelution for
    dc_niter=100
    
    // Number of planes arround the center of PSF to use for decon. Defaults to all in PSF
    dc_psf_crop_z=null
    
    // Select every x planes starting from the center of the PSF. This is usefull if the PSF
    // image has higher z resolution then the image. For example, if the PSF has 100nm spacing
    // and the image has 500nm spacing, set this to 5.
    // dc_psf_crop_z is applied AFTER this.
    dc_psf_subsample_z=null
    
    // Implementation of richardson lucy to use
    // clij2 = clij2-fft richardson_lucy
    // clij2_nc = clij2-fft non circulant richardson_lucy
    // rlf_cpu = RedLionFish in CPU mode
    // rlf_gpu = RedLionFish in GPU mode
    // RedLionFish is not reccomended when there are strong edges in the data
    dc_mode="clij2_nc"
    
    // Regularization parameter for Richardson Lucy
    // Only used for mode clij2 and clij2_nc
    // Set to default, more detaills here:
    // https://forum.image.sc/t/richardson-lucy-deconvolution-large-images/85325/7
    // https://pubmed.ncbi.nlm.nih.gov/24436314/
    dc_regularization=0.0002
    
    // Pixel value to clip to after deconvolution in 32>16 bit conversion.
    // new_intensity = round((intensity / dc_clip_max) * 65535)
    // Under defaults, an intensity of 100, will become 20 in the decon output. 
    // Values lower then this will be preserved, but might loose precision, Values
    // higher then this will become 65535 in the 16 bit output.
    // Set to 65535 to clip everything outside the 16 bit range, but preserve dynamic range.
    // set to > 65535 to scale values down, but keep the dynamic range in the upper end.
    // Defaults to 5*65535=327675
    // IMPORTANT: To be able to interpret the intensities between runs, keep this parameter
    // consistent, as it will scale the intensity range!
    dc_clip_max=327675
    
    // ---------------------------------------------------------------------------------- //
    //                                      Tglow
    // ---------------------------------------------------------------------------------- //
    // Tglow conda env
    tg_conda_env = "/software/teamtrynka/installs/tglow"

    // [DEPRECATED]
    // Now uses nextflows ./bin functionality
    // Dir to find tglow scripts
    //tg_core_dir="/software/teamtrynka/installs/tglow-core/runners"

    // ---------------------------------------------------------------------------------- //
    //                                  Cellprofiler
    // ---------------------------------------------------------------------------------- //
    // Label to execute cellprofiler process under
    // "normal" 2h, 16gb
    // "medium" 12h, 32gb
    cpr_label="normal"
        
    // cellprofiler conda env
    cpr_conda_env="/software/teamtrynka/installs/cellprofiler"
    
    // cellprofiler plugins
    // Place cellprofiler plugin files either in ./bin/cellprofiler/plugins 
    // or supply --cpr_plugins at runtime
    cpr_plugins="$projectDir/bin/cellprofiler/plugins"
    
    // Execute  cellprofiler
    cpr_run=false
    
    // cellprofiler pipeline for max projections
    cpr_pipeline_2d=null
    
    // cellprofiler pipeline for 3d
    cpr_pipeline_3d=null
    
    // Do not zip cellprofiler output into one archive
    cpr_no_zip=false
    
    
    // ---------------------------------------------------------------------------------- //
    //                                  Subcell
    // ---------------------------------------------------------------------------------- //
    // Resrouce label, reccomend normal or gpu_normal
    sc_label="gpu_short"
    
    // Should GPU be used, make sure to set sc_label to gpu_normal!
    sc_gpu=true
    
    // Should the cell crops not be masked by the cell object prior to embedding
    sc_dont_mask=false
    
    // Conda env to use
    sc_conda_env="/software/teamtrynka/installs/subcell"
    sc_dl_conda_env="/software/teamtrynka/installs/subcell_model_dl"

    // SubCell model reference channels, see subcell docs or assets folder for options
    sc_model_ref_channels="rybg"
    
    // SubCell model, see subcell docs or assets folder for options
    sc_model="mae_contrast_supcon_model"

    // Channels to find localization for. Should be string '<name>=<channel> <name>=<channel>'
    sc_channels=null
    
    // Nuclues, tubilin, er channels
    sc_nucl=null
    sc_tub=null
    sc_er=null
    
    // Scale factor to get pixel size to 80nm. In Phenix 1px=149nm at 40x, so sc_scale=149/80
    // TODO: set this so properly uses the physical pixel sizes attribute if available
    sc_scale=1.8625
    
    
}

